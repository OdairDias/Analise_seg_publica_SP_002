import requests
from bs4 import BeautifulSoup
import boto3

# Make a request to the website
page = requests.get('https://www.example.com/data')

# Parse the HTML content of the page
soup = BeautifulSoup(page.content, 'html.parser')

# Find the data we want to scrape
data = soup.find_all('div', class_='data-item')

# Store the data in a list
data_list = []
for item in data:
    data_list.append(item.text)

# Save the data to a file
with open('data.txt', 'w') as f:
    for item in data_list:
        f.write(item + '\n')

# Connect to Amazon S3
s3 = boto3.client('s3')

# Upload the file to the bucket
s3.upload_file('data.txt', 'my-bucket', 'data.txt')
